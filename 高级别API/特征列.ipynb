{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征列\n",
    "本文档详细介绍了特征列。您可以将特征列视为原始数据和 Estimator 之间的媒介。特征列内容丰富，使您可以将各种原始数据转换为 Estimator 可以使用的格式，从而可以轻松地进行实验。\n",
    "\n",
    "通过 Estimator（鸢尾花的 DNNClassifier）的 feature_columns 参数指定模型的输入。特征列在输入数据（由 input_fn 返回）与模型之间架起了桥梁。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数值列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defaults to a tf.float32 scalar.\n",
    "numeric_feature_column = tf.feature_column.numeric_column(key=\"SepalLength\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represent a tf.float64 scalar.\n",
    "numeric_feature_column = tf.feature_column.numeric_column(key=\"SepalLength\",\n",
    "                                                          dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represent a 10-element vector in which each cell contains a tf.float32.\n",
    "vector_feature_column = tf.feature_column.numeric_column(key=\"Bowling\",\n",
    "                                                         shape=10)\n",
    "\n",
    "# Represent a 10x5 matrix in which each cell contains a tf.float32.\n",
    "matrix_feature_column = tf.feature_column.numeric_column(key=\"MyMatrix\",\n",
    "                                                         shape=[10,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分桶列\n",
    "根据数值范围将其值分为不同的类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, convert the raw input to a numeric column.\n",
    "numeric_feature_column = tf.feature_column.numeric_column(\"Year\")\n",
    "\n",
    "# Then, bucketize the numeric column on the years 1960, 1980, and 2000.\n",
    "bucketized_feature_column = tf.feature_column.bucketized_column(\n",
    "    source_column = numeric_feature_column,\n",
    "    boundaries = [1960, 1980, 2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分类标识列\n",
    "分类标识列是分桶列的一种特殊情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create categorical output for an integer feature named \"my_feature_b\",\n",
    "# The values of my_feature_b must be >= 0 and < num_buckets\n",
    "identity_feature_column = tf.feature_column.categorical_column_with_identity(\n",
    "    key='my_feature_b',\n",
    "    num_buckets=4) # Values [0, 4)\n",
    "\n",
    "# In order for the preceding call to work, the input_fn() must return\n",
    "# a dictionary containing 'my_feature_b' as a key. Furthermore, the values\n",
    "# assigned to 'my_feature_b' must belong to the set [0, 4).\n",
    "def input_fn():\n",
    "    ...\n",
    "    return ({ 'my_feature_a':[7, 9, 5, 2], 'my_feature_b':[3, 1, 2, 2] },\n",
    "            [Label_values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分类词汇列\n",
    "1、tf.feature_column.categorical_column_with_vocabulary_list\n",
    "\n",
    "2、tf.feature_column.categorical_column_with_vocabulary_file"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "categorical_column_with_vocabulary_list 根据明确的词汇表将每个字符串映射到一个整数。它有一个明显的缺点。那就是，当词汇表很长时，需要输入的内容太多了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given input \"feature_name_from_input_fn\" which is a string,\n",
    "# create a categorical feature by mapping the input to one of\n",
    "# the elements in the vocabulary list.\n",
    "vocabulary_feature_column = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        key=feature_name_from_input_fn,\n",
    "        vocabulary_list=[\"kitchenware\", \"electronics\", \"sports\"])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tf.feature_column.categorical_column_with_vocabulary_file 可将词汇放在单独的文件中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given input \"feature_name_from_input_fn\" which is a string,\n",
    "# create a categorical feature to our model by mapping the input to one of\n",
    "# the elements in the vocabulary file\n",
    "vocabulary_feature_column =\n",
    "    tf.feature_column.categorical_column_with_vocabulary_file(\n",
    "        key=feature_name_from_input_fn,\n",
    "        vocabulary_file=\"product_class.txt\",\n",
    "        vocabulary_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 经过哈希处理的列\n",
    "到目前为止，我们处理的示例都包含很少的类别。例如，我们的 product_class 示例只有 3 个类别。但是通常，类别的数量非常大，以至于无法为每个词汇或整数设置单独的类别，因为这会消耗太多内存。对于此类情况，我们可以反问自己：“我愿意为我的输入设置多少类别？”实际上，tf.feature_column.categorical_column_with_hash_bucket 函数使您能够指定类别的数量。对于这种类型的特征列，模型会计算输入的哈希值，然后使用模运算符将其置于其中一个 hash_bucket_size 类别中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudocode\n",
    "feature_id = hash(raw_feature) % hash_buckets_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashed_feature_column =\n",
    "    tf.feature_column.categorical_column_with_hash_bucket(\n",
    "        key = \"some_feature\",\n",
    "        hash_buckets_size = 100) # The number of categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 组合列\n",
    "通过将多个特征组合为一个特征（称为特征组合），模型可学习每个特征组合的单独权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(latitude, longitude, labels):\n",
    "    assert latitude.shape == longitude.shape == labels.shape\n",
    "\n",
    "    features = {'latitude': latitude.flatten(),\n",
    "                'longitude': longitude.flatten()}\n",
    "    labels=labels.flatten()\n",
    "\n",
    "    return tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "\n",
    "# Bucketize the latitude and longitude usig the `edges`\n",
    "latitude_bucket_fc = tf.feature_column.bucketized_column(\n",
    "    tf.feature_column.numeric_column('latitude'),\n",
    "    list(atlanta.latitude.edges))\n",
    "\n",
    "longitude_bucket_fc = tf.feature_column.bucketized_column(\n",
    "    tf.feature_column.numeric_column('longitude'),\n",
    "    list(atlanta.longitude.edges))\n",
    "\n",
    "# Cross the bucketized columns, using 5000 hash bins.\n",
    "crossed_lat_lon_fc = tf.feature_column.crossed_column(\n",
    "    [latitude_bucket_fc, longitude_bucket_fc], 5000)\n",
    "\n",
    "fc = [\n",
    "    latitude_bucket_fc,\n",
    "    longitude_bucket_fc,\n",
    "    crossed_lat_lon_fc]\n",
    "\n",
    "# Build and train the Estimator.\n",
    "est = tf.estimator.LinearRegressor(fc, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 指标列和嵌入列\n",
    "指标列和嵌入列从不直接处理特征，而是将分类列视为输入。\n",
    "指标列将每个类别视为独热矢量中的一个元素，其中匹配类别的值为 1，其余类别为 0\n",
    "\n",
    "嵌入列并非将数据表示为很多维度的独热矢量，而是将数据表示为低维度普通矢量，其中每个单元格可以包含任意数字，而不仅仅是 0 或 1。通过使每个单元格能够包含更丰富的数字，嵌入列包含的单元格数量远远少于指标列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_column = ... # Create any type of categorical column.\n",
    "\n",
    "# Represent the categorical column as an indicator column.\n",
    "indicator_column = tf.feature_column.indicator_column(categorical_column)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "调用 tf.feature_column.embedding_column 来创建一个 embedding_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_column = ... # Create any categorical column\n",
    "\n",
    "# Represent the categorical column as an embedding column.\n",
    "# This means creating a one-hot vector with one element for each category.\n",
    "embedding_column = tf.feature_column.embedding_column(\n",
    "    categorical_column=categorical_column,\n",
    "    dimension=dimension_of_embedding_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将特征列传递给 Estimator\n",
    "将特征列传递给 Estimator\n",
    "如下面的列表所示，并非所有 Estimator 都支持所有类型的 feature_columns 参数：\n",
    "\n",
    "    LinearClassifier 和 LinearRegressor：接受所有类型的特征列。\n",
    "\n",
    "    DNNClassifier 和 DNNRegressor：只接受密集列。其他类型的列必须封装在 indicator_column 或 embedding_column 中。\n",
    "\n",
    "    DNNLinearCombinedClassifier 和 DNNLinearCombinedRegressor：\n",
    "\n",
    "    linear_feature_columns 参数接受任何类型的特征列。\n",
    "\n",
    "    dnn_feature_columns 参数只接受密集列。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "注意：部分程序之作理解使用，由于程序不完整故不能运行"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
