{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "TEST_URL =  \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "CSV_COLUMN_NAMES =  ['SepalLength', 'SepalWidth',\n",
    "                    'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
    "\n",
    "def load_data(label_name='Species'):\n",
    "    #训练集\n",
    "    train_path = tf.keras.utils.get_file(fname=os.path.basename(TRAIN_URL),\n",
    "                                         origin=TRAIN_URL)\n",
    "    train = pd.read_csv(train_path,names=CSV_COLUMN_NAMES,header=0)\n",
    "    \n",
    "    train_features,train_labels = train,train.pop(label_name)\n",
    "    #测试集\n",
    "    test_path = tf.keras.utils.get_file(fname=os.path.basename(TEST_URL),\n",
    "                                       origin=TEST_URL)\n",
    "    test = pd.read_csv(test_path,names=CSV_COLUMN_NAMES,header=0)\n",
    "    \n",
    "    test_features,test_labels = test,test.pop(label_name)\n",
    "    \n",
    "    return (train_features,train_labels),(test_features,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
      "0          6.4         2.8          5.6         2.2\n",
      "1          5.0         2.3          3.3         1.0\n",
      "2          4.9         2.5          4.5         1.7\n",
      "3          4.9         3.1          1.5         0.1\n",
      "4          5.7         3.8          1.7         0.3\n",
      "0    2\n",
      "1    1\n",
      "2    2\n",
      "3    0\n",
      "4    0\n",
      "Name: Species, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "(train_x,train_y),(test_x,test_y) = load_data()\n",
    "print(train_x[:5])\n",
    "print(train_y[:5])\n",
    "print(type(train_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth'], dtype='object')\n",
      "[_NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), _NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), _NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), _NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "feature_columns = []\n",
    "print(train_x.keys())\n",
    "for key in train_x.keys():\n",
    "    feature_columns.append(tf.feature_column.numeric_column(key=key)) \n",
    "print(feature_columns)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "首先我们来看看预制估算器的结构,以tesnsorflow里面自带的深度神经分类器tf.estimator.DNNClassifier为例"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tf.estimator.DNNClassifier(hidden_units, feature_columns, model_dir=None, n_classes=2, weight_column=None, label_vocabulary=None, optimizer='Adagrad', activation_fn=<function relu at 0x000001F617FB7730>, dropout=None, input_layer_partitioner=None, config=None, warm_start_from=None, loss_reduction='weighted_sum', batch_norm=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "其中iris案例的用到的参数如下："
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "classifier = tf.estimator.DNNClassifier(\n",
    "    \n",
    "    feature_columns=feature_columns,#特征列\n",
    "    hidden_units=[10, 10],#隐藏层神经元个数\n",
    "    n_classes=3,#类的个数\n",
    "    model_dir=models_path,#储存目录\n",
    "    config=ckpt_config#`RunConfig`对象用于配置运行时设置参数对象\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "在Tensorflow中我们同样可以使用tf.estimator.Estimitor()方法自定义我们需要的分类器\n",
    "如下图所示，欲创建的Estimator是tf.estimator.Estimator基类的一个子类，而自定义Estimator是tf.estimator.Estimator的实例："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Estimitor.webp\" style=\"width:400px;height:200px;\">"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "自定义估算器语法格式如下："
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tf.estimator.Estimator(\n",
    "    model_fn, #模型函数\n",
    "    model_dir=None, #储存目录\n",
    "    config=None, #设置参数对象\n",
    "    params=None,#超参数，将传递给model_fn使用 \n",
    "    warm_start_from=None#热启动目录路径\n",
    "    )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "自定义估算器分别使用train(),evaluate(),predic()三个方法来训练，评估，预测.\n",
    "\n",
    "以iris为例，params接收的超参数有 feature_columns,hidden_units,n_classes.\n",
    "\n",
    "params{\n",
    "    \n",
    "    \"feature_column\":...\n",
    "    \"hidden_units\":[10,10]\n",
    "    \"n_classes\":3\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_fn函数如下："
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def model_fn(\n",
    "    features,#数据特征\n",
    "    labels,#数据标签\n",
    "    mode,#train，valuate，predict\n",
    "    params#超参数，对应上面Estimator传来的参数\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造model_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先我们需要了解iris神经网络结构：\n",
    "<img src=\"model_fn.webp\" style=\"width:400px;height:200px;\">"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "如上图所示，我们发现该网络由Input Layer，Hidden Layer，Output Layer三个层组成，下面我们来分别仔细了解这三个层：\n",
    "- 输入层（Input Layer）:输入数据\n",
    "- 隐藏层 (Hidden Layer)：2个隐藏层，每个隐藏层都有10个神经元（增加模型复杂度）用来捕捉特征，每个隐藏层就是一个 特征代表层 (feature representation).\n",
    "- 输出层 (Output Layer)：输出每个类的概率"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def model_fn(feature,labels,mode,params):\n",
    "    #输入层\n",
    "    net = tf.feature_column.input_layer(features=features,\n",
    "                                        feature_columns=params['feature_column'])\n",
    "    #隐藏层\n",
    "    for unit in params['hidden_units']:\n",
    "        net = tf.layers.dense(inputs=net,units=units,activation=tf.nn.relu)\n",
    "    \n",
    "    #输出层\n",
    "    logits = tf.layers.dense(inputs=net,units=params['n_classes'],activation=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输入层 Input Layer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "如下图所示，Input Layer把输入的数据features填充到特征列params['feature_column']里面,稍后它会被继续传递到隐藏层hidden layer："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Input Layer.webp\" style=\"width:400px;height:200px;\">"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "输入层input layer - 隐藏层Hidden Layer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "我们使用循环为hidden_unit列表([10,10])创建了2个隐藏图层，每个图层的神经元节点unit都等于10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"link.webp\" style=\"width:400px;height:200px;\">"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "输入层input layer - 隐藏层Hidden Layer - 输入层Output Layer\n",
    "\n",
    "其中输出的[-1.3,2.6,-0.9]表示三种类的可能性，后续会对其进行转化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"link1.webp\" style=\"width:400px;height:200px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "自定义估算器里面有三种mode分别是PREDICT（预测）、EVAL（评估）、TRAIN（训练）\n",
    "用法类比欲制估算器里面的predict()、evaluate（）、train（）三种方法。\n",
    "\n",
    "tf.estimator.DNNClassifier.predict()  --->  my_classifier.predict()\n",
    "tf.estimator.DNNClassifier.evaluate() --->  my_classifier.evaluate()\n",
    "tf.estimator.DNNClassifier.train()    --->  my_classifier.train()\n",
    "\n",
    "如果第三个参数mode等于\"TRAIN\"我们就执行训练，如下所示\n",
    "my_model_fn(features,labels,mode =\"TRAIN\",params)\n",
    "如果是“EVAL”就执行评价，“PREDICT”就执行预测。\n",
    "\n",
    "根据值mode，需要不同的参数。亦即\n",
    "\n",
    "对于mode == ModeKeys.TRAIN：必填字段是loss和train_op。\n",
    "对于mode == ModeKeys.EVAL：必填字段是loss。\n",
    "对于mode == ModeKeys.PREDICT：必填字段predictions。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model_fn(features,labels,mode,params):\n",
    "    \n",
    "    #输入层\n",
    "    net = tf.feature_column.input_layer(features,params['feature_columns'])\n",
    "    \n",
    "    #隐藏层\n",
    "    for units in params['hidden_units']:\n",
    "        net = tf.layers.dense(net, units=units, activation=tf.nn.relu)\n",
    "        \n",
    "    #输出层\n",
    "    logits = tf.layers.dense(net,params['n_classes'],activation=None)\n",
    "    \n",
    "    #预测\n",
    "    predicted_classes = tf.argmax(logits,1) #预测的结果中最大值即种类\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            'class_ids':predicted_classes[:,tf.newaxis],#[1 2 3 4]-->[[1],[2],[3],[4]]\n",
    "            'logits':logits,#[-1.3,2.6,1.9]\n",
    "            'probabilities':tf.nn.softmax(logits)#把[-1.3,2.6,-0.9]规则化到0~1范围,表示可能性\n",
    "        }\n",
    "        #Ops和对象从`model_fn`返回并传递给`Estimator`。\n",
    "        return tf.estimator.EstimatorSpec(mode,predictions=predictions)\n",
    "    \n",
    "    #损失函数\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels,logits=logits)\n",
    "    \n",
    "    #训练\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        #优化器\n",
    "        optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
    "        train_op = optimizer.minimize(loss,global_step=tf.train.get_global_step())\n",
    "        return  tf.estimator.EstimatorSpec(mode,loss=loss,train_op=train_op)\n",
    "    \n",
    "    #评估\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        accuracy = tf.metrics.accuracy(labels=labels,\n",
    "                                       predictions=predicted_classes,\n",
    "                                   name='acc_op')\n",
    "        metrics = {'accuracy':accuracy}\n",
    "        #为图表统计使用\n",
    "        tf.summary.scalar('accuracy',accuracy[1])\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "EstimatorSpec完全定义了由Estimator运行的模型。\n",
    "根据值mode，需要不同的参数。亦即\n",
    "·对于mode == ModeKeys.TRAIN：必填字段是loss和train_op。\n",
    "·对于mode == ModeKeys.EVAL：必填字段是loss。\n",
    "·对于mode == ModeKeys.PREDICT：必填字段predictions。\n",
    "\n",
    "tf.estimator.EstimatorSpec()参数说明：\n",
    "·mode：A ModeKeys。指定这是训练，评估还是预测。\n",
    "·predictions：预测Tensor或词典Tensor。\n",
    "·loss：训练损失Tensor。必须是标量或形状[1]。\n",
    "·train_op：Op为训练步骤。\n",
    "·eval_metric_ops：按名称键入的度量结果的字典。dict的值是调用度量函数的结果，即        (metric_tensor, update_op)元组。metric_tensor应该在不对状态产生任何影响的情况下进行评估（通常是基于变量的纯计算结果）。例如，它不应该触发update_op 或需要任何输入提取。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#修改创建估算分类器的代码设置model_dir模型保存与自动恢复,并设定日志打印\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "models_path=os.path.join(os.getcwd(),'mymodels/')\n",
    "\n",
    "#创建自定义分类器\n",
    "classifier = tf.estimator.Estimator(\n",
    "        model_fn=my_model_fn,\n",
    "        model_dir=models_path,\n",
    "        params={\n",
    "            'feature_columns': feature_columns,\n",
    "            'hidden_units': [10, 10],\n",
    "            'n_classes': 3,\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into E:\\jupyter\\tensorflow\\Tensorflow官方文档\\高级别API\\mymodels/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.0648383, step = 1\n",
      "INFO:tensorflow:global_step/sec: 624.844\n",
      "INFO:tensorflow:loss = 0.14669049, step = 101 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 997.724\n",
      "INFO:tensorflow:loss = 0.0793827, step = 201 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 909.808\n",
      "INFO:tensorflow:loss = 0.0722641, step = 301 (0.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 908.842\n",
      "INFO:tensorflow:loss = 0.06607108, step = 401 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 1002.54\n",
      "INFO:tensorflow:loss = 0.08030492, step = 501 (0.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 907.416\n",
      "INFO:tensorflow:loss = 0.034899995, step = 601 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 1001.03\n",
      "INFO:tensorflow:loss = 0.036540054, step = 701 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 906.73\n",
      "INFO:tensorflow:loss = 0.08475001, step = 801 (0.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 910.392\n",
      "INFO:tensorflow:loss = 0.034411732, step = 901 (0.120 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into E:\\jupyter\\tensorflow\\Tensorflow官方文档\\高级别API\\mymodels/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.06904268.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x1d23837b7b8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#针对训练的喂食函数\n",
    "batch_size=100\n",
    "def train_input_fn(features, labels, batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    dataset = dataset.shuffle(1000).repeat().batch(batch_size) #每次随机调整数据顺序\n",
    "    return dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "#开始训练\n",
    "classifier.train(\n",
    "    input_fn=lambda:train_input_fn(train_x, train_y, 100),\n",
    "    steps=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评价模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-09-06-08:20:20\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from E:\\jupyter\\tensorflow\\Tensorflow官方文档\\高级别API\\mymodels/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-09-06-08:20:20\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.96666664, global_step = 1000, loss = 0.058778085\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: E:\\jupyter\\tensorflow\\Tensorflow官方文档\\高级别API\\mymodels/model.ckpt-1000\n",
      "{'accuracy': 0.96666664, 'loss': 0.058778085, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "def eval_input_fn(features,labels,batch_size):\n",
    "    features = dict(features)\n",
    "    inputs = (features,labels)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    return dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "#开始评估\n",
    "eval_results = classifier.evaluate(\n",
    "    input_fn = lambda:eval_input_fn(test_x,test_y,batch_size)\n",
    ")\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please enter features: SepalLength,SepalWidth,PetalLength,PetalWidth\n",
      "1,2,3,4\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from E:\\jupyter\\tensorflow\\Tensorflow官方文档\\高级别API\\mymodels/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Virginica 99.99525547027588\n",
      "\n",
      "Please enter features: SepalLength,SepalWidth,PetalLength,PetalWidth\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,100):\n",
    "    print('\\nPlease enter features: SepalLength,SepalWidth,PetalLength,PetalWidth')\n",
    "    a,b,c,d = map(float,input().split(','))#捕捉用户输入数字\n",
    "    predict_x = {\n",
    "        'SepalLength': [a],\n",
    "        'SepalWidth': [b],\n",
    "        'PetalLength': [c],\n",
    "        'PetalWidth': [d],\n",
    "    }\n",
    "    predictions = classifier.predict(input_fn=lambda:eval_input_fn(predict_x,\n",
    "                                                                   labels=[0,],\n",
    "                                                                   batch_size=batch_size))\n",
    "    \n",
    "    for pred_dict in predictions:\n",
    "        class_id = pred_dict['class_ids'][0]\n",
    "        probability = pred_dict['probabilities'][class_id]\n",
    "        print(SPECIES[class_id],100 * probability)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
