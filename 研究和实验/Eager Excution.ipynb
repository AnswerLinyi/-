{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入tensorflow模块并启用急切执行 \n",
    "Eager Excution可以为TensorFlow提供更具交互性的前端"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.10.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor\n",
    "张量是一个多维数组。 与NumPy ndarray对象类似，Tensor对象具有数据类型和形状。 此外，Tensors可以驻留在加速器（如GPU）内存中。 TensorFlow提供了丰富的操作库（tf.add，tf.matmul，tf.linalg.inv等），它们使用和生成Tensors。 这些操作自动转换本机Python类型。 例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor([4 6], shape=(2,), dtype=int32)\n",
      "tf.Tensor(25, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(b'aGVsbG8gd29ybGQ', shape=(), dtype=string)\n",
      "tf.Tensor(13, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.add(1,2))\n",
    "print(tf.add([1,2],[3,4]))\n",
    "print(tf.square(5))\n",
    "print(tf.reduce_sum([1,2,3]))\n",
    "print(tf.encode_base64(\"hello world\"))\n",
    "\n",
    "print(tf.square(2) + tf.square(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "<dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "x = tf.matmul([[1]],[[2,3]])\n",
    "print(x.shape)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "NumPy阵列和TensorFlow张量之间最明显的区别是：\n",
    "\n",
    "张量可以由加速器内存（如GPU，TPU）支持。\n",
    "张量是不可改变的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy兼容性\n",
    "\n",
    "TensorFlow张量和NumPy nararrays之间的转换非常简单，如：\n",
    "\n",
    "- TensorFlow操作自动将NumPy ndarrays转换为Tensors。\n",
    "- NumPy操作自动将Tensors转换为NumPy ndarrays。\n",
    "\n",
    "通过在它们上调用.numpy（）方法，可以将张量显式转换为NumPy ndarrays。 这些转换通常很便宜，因为如果可能，数组和Tensor共享底层内存表示。 但是，共享底层表示并不总是可行的，因为Tensor可能托管在GPU内存中，而NumPy阵列总是由主机内存支持，因此转换将涉及从GPU到主机内存的复制。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow operation convert numpy arrays to Tensors automatically\n",
      "tf.Tensor(\n",
      "[[42. 42. 42.]\n",
      " [42. 42. 42.]\n",
      " [42. 42. 42.]], shape=(3, 3), dtype=float64)\n",
      "And Numpy operations convert Tensors to numpy array automatically\n",
      "[[43. 43. 43.]\n",
      " [43. 43. 43.]\n",
      " [43. 43. 43.]]\n",
      "The.numpy() method explicitly converts a Tensor to a numpy array\n",
      "[[42. 42. 42.]\n",
      " [42. 42. 42.]\n",
      " [42. 42. 42.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ndarray = np.ones([3,3])\n",
    "\n",
    "print(\"Tensorflow operation convert numpy arrays to Tensors automatically\")\n",
    "tensor = tf.multiply(ndarray,42)\n",
    "print(tensor)\n",
    "\n",
    "print(\"And Numpy operations convert Tensors to numpy array automatically\")\n",
    "print(np.add(tensor,1))\n",
    "\n",
    "print(\"The.numpy() method explicitly converts a Tensor to a numpy array\")\n",
    "print(tensor.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU 加速"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过使用GPU进行计算，可以加速许多TensorFlow操作。 在没有任何注释的情况下，TensorFlow会自动决定是使用GPU还是CPU进行操作（如有必要，还可以复制CPU和GPU内存之间的张量）。 由操作产生的张量通常由执行操作的设备的存储器支持。 例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is There a GPU avaliable:\n",
      "False\n",
      "Is the Tensor on GPU #0: \n",
      "False\n"
     ]
    }
   ],
   "source": [
    "x = tf.random_uniform([3,3])\n",
    "\n",
    "print(\"Is There a GPU avaliable:\")\n",
    "print(tf.test.is_gpu_available())\n",
    "\n",
    "print(\"Is the Tensor on GPU #0: \")\n",
    "print(x.device.endswith('GPU:0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设备名称\n",
    "Tensor.device属性提供托管Tensor内容的设备的完全限定字符串名称。 此名称对一组详细信息进行编码，例如，正在执行此程序的主机的网络地址的标识符以及该主机中的设备。 这是分布式执行TensorFlow程序所必需的，但我们暂时不会这样做。 如果张量位于主机上的第N个张量上，则字符串将以GPU结尾：<N>。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 显式设备放置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow中的术语“放置”指的是如何为执行设备分配（放置）各个操作。 如上所述，当没有提供明确的指导时，TensorFlow会自动决定执行操作的设备，并在需要时将Tensors复制到该设备。 但是，可以使用tf.device上下文管理器将TensorFlow操作显式放置在特定设备上。 例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On CPU:\n"
     ]
    }
   ],
   "source": [
    "def time_matmul(x):\n",
    "    %timeit tf.matmul(x,x)\n",
    "\n",
    "# Force execution on CPU\n",
    "print(\"On CPU:\")\n",
    "with tf.device(\"CPU:0\"):\n",
    "    x = tf.random_uniform([1000,1000])\n",
    "    assert x.device.endswith(\"CPU:0\")\n",
    "    time_matmul(x)\n",
    "\n",
    "# Force execution on GPU #0 if available\n",
    "if tf.test.is_gpu_available():\n",
    "    with tf.device(\"GPU:0\"):\n",
    "        x = tf.random_uniform([1000,1000])\n",
    "        assert x.device.endswith(\"GPU:0\")\n",
    "        time_matmul(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本节演示如何使用tf.data.Dataset API构建管道以将数据提供给模型。 它涵盖：\n",
    "\n",
    "- 创建数据集。\n",
    "- 在启用了急切执行的情况下对数据集进行迭代。\n",
    "\n",
    "我们建议使用数据集API从简单，可重复使用的部分构建高性能，复杂的输入管道，这些部分将为模型的培训或评估循环提供支持。\n",
    "\n",
    "如果您熟悉TensorFlow图，则在启用eager执行时，构建数据集对象的API保持完全相同，但迭代数据集元素的过程稍微简单一些。 您可以对tf.data.Dataset对象使用Python迭代，而不需要显式创建tf.data.Iterator对象。 因此，在启用eager执行时，TensorFlow指南中对迭代器的讨论无关紧要。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a source Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用其中一个工厂函数（如Dataset.from_tensors，Dataset.from_tensor_slices）或使用从TextLineDataset或TFRecordDataset等文件读取的对象创建源数据集。 有关更多信息，请参阅TensorFlow指南。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tensors = tf.data.Dataset.from_tensor_slices([1,2,3,4,5,6])\n",
    "\n",
    "#Create a CSV file\n",
    "import tempfile\n",
    "_,filename = tempfile.mkstemp()\n",
    "\n",
    "with open(filename,'w') as f:\n",
    "    f.write(\"\"\"Line 1\n",
    "    Line 2\n",
    "    Line 3\n",
    "    \"\"\")\n",
    "ds_file = tf.data.TextLineDataset(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 应用转换\n",
    "使用map，batch，shuffle等转换函数将转换应用于数据集的记录。 有关详细信息，请参阅tf.data.Dataset的API文档。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tensors = ds_tensors.map(tf.square).shuffle(2).batch(2)\n",
    "\n",
    "ds_file = ds_file.batch(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 迭代\n",
    "启用eager执行时，Dataset对象支持迭代。 如果您熟悉TensorFlow图中数据集的使用，请注意不需要调用Dataset.make_one_shot_iterator（）或get_next（）调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Elements of ds_tensors:')\n",
    "for x in ds_tensors:\n",
    "    print(x.numpy())\n",
    "\n",
    "print(\"\\nElements in ds_file:\")\n",
    "for x in ds_file:\n",
    "    print(x.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
