{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建自定义 Estimator\n",
    "本文档介绍了自定义 Estimator。具体而言，本文档介绍了如何创建自定义 Estimator 来模拟预创建的 Estimator DNNClassifier 在解决鸢尾花问题时的行为。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预创建的 Estimator 与自定义 Estimator\n",
    "预创建的 Estimator 是 tf.estimator.Estimator 基类的子类，而自定义 Estimator 是 tf.estimator.Estimator 的实例\n",
    "\n",
    "预创建的 Estimator 已完全成形。不过有时，您需要更好地控制 Estimator 的行为。这时，自定义 Estimator 就派上用场了。您可以创建自定义 Estimator 来完成几乎任何操作。如果您需要以某种不寻常的方式连接隐藏层，则可以编写自定义 Estimator。如果您需要为模型计算独特的指标，也可以编写自定义 Estimator。基本而言，如果您需要一个针对具体问题进行了优化的 Estimator，就可以编写自定义 Estimator。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import iris_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "TEST_URL =  \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "CSV_COLUMN_NAMES =  ['SepalLength', 'SepalWidth',\n",
    "                    'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
    "def load_data(label_name = 'Species'):\n",
    "    train_path = tf.keras.utils.get_file(fname=os.path.basename(TRAIN_URL),\n",
    "                                        origin = TRAIN_URL)\n",
    "    train = pd.read_csv(train_path,names=CSV_COLUMN_NAMES,header=0)\n",
    "    \n",
    "    train_features,train_label = train,train.pop(label_name)\n",
    "    \n",
    "    test_path = tf.keras.utils.get_file(fname=os.path.basename(TEST_URL),\n",
    "                                       origin=TEST_URL)\n",
    "    test = pd.read_csv(test_path,names=CSV_COLUMN_NAMES,header=0)\n",
    "    \n",
    "    test_features,test_label = test,test.pop(label_name)\n",
    "    \n",
    "    return (train_features,train_label),(test_features,test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
      "0          6.4         2.8          5.6         2.2\n",
      "1          5.0         2.3          3.3         1.0\n",
      "2          4.9         2.5          4.5         1.7\n",
      "3          4.9         3.1          1.5         0.1\n",
      "4          5.7         3.8          1.7         0.3\n"
     ]
    }
   ],
   "source": [
    "(train_x,train_y),(test_x,test_y) = load_data()\n",
    "print(train_x[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编写输入函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn(features,labels,batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features),labels))\n",
    "    dataset = dataset.shuffle(1000).repeat(None).batch(batch_size)\n",
    "    return dataset.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建特征列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_feature_columns = []\n",
    "for key in train_x.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编写模型函数\n",
    "前两个参数是从输入函数中返回的特征和标签批次；也就是说，features 和 labels 是模型将使用的数据的句柄。mode 参数表示调用程序是请求训练、预测还是评估。\n",
    "\n",
    "调用程序可以将 params 传递给 Estimator 的构造函数。传递给构造函数的所有 params 转而又传递给 model_fn。在 custom_estimator.py 中，以下行将创建 Estimator 并设置参数来配置模型。此配置步骤与我们配置 tf.estimator.DNNClassifier（在预创建的 Estimator 中）的方式相似。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model(features, labels, mode, params):\n",
    "    \"\"\"DNN with three hidden layers, and dropout of 0.1 probability.\"\"\"\n",
    "    # Create three fully connected layers each layer having a dropout\n",
    "    # probability of 0.1.\n",
    "    net = tf.feature_column.input_layer(features, params['feature_columns'])\n",
    "    for units in params['hidden_units']:\n",
    "        net = tf.layers.dense(net, units=units, activation=tf.nn.relu)\n",
    "\n",
    "    # Compute logits (1 per class).\n",
    "    logits = tf.layers.dense(net, params['n_classes'], activation=None)\n",
    "\n",
    "    # Compute predictions.\n",
    "    predicted_classes = tf.argmax(logits, 1)\n",
    "    print(predicted_classes.shape)\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            'class_ids': predicted_classes[:, tf.newaxis],\n",
    "            'probabilities': tf.nn.softmax(logits),\n",
    "            'logits': logits,\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "    # Compute loss.\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "    # Compute evaluation metrics.\n",
    "    accuracy = tf.metrics.accuracy(labels=labels,\n",
    "                                   predictions=predicted_classes,\n",
    "                                   name='acc_op')\n",
    "    metrics = {'accuracy': accuracy}\n",
    "    tf.summary.scalar('accuracy', accuracy[1])\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode, loss=loss, eval_metric_ops=metrics)\n",
    "\n",
    "    # Create training op.\n",
    "    assert mode == tf.estimator.ModeKeys.TRAIN\n",
    "\n",
    "    optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
    "    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定义Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\THINK\\AppData\\Local\\Temp\\tmponjwn7__\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\THINK\\\\AppData\\\\Local\\\\Temp\\\\tmponjwn7__', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000195D277E550>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "    # Build 2 hidden layer DNN with 10, 10 units respectively.\n",
    "    classifier = tf.estimator.Estimator(\n",
    "        model_fn=my_model,\n",
    "        params={\n",
    "            'feature_columns': my_feature_columns,\n",
    "            # Two hidden layers of 10 nodes each.\n",
    "            'hidden_units': [10, 10],\n",
    "            # The model must choose between 3 classes.\n",
    "            'n_classes': 3,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "(?,)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\THINK\\AppData\\Local\\Temp\\tmponjwn7__\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.8297886, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 50 into C:\\Users\\THINK\\AppData\\Local\\Temp\\tmponjwn7__\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.33193043.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x195d277efd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Model.\n",
    "classifier.train(\n",
    "    input_fn=lambda:train_input_fn(train_x, train_y, 1000),\n",
    "    steps= 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不懂的地方可以关注 https://www.jianshu.com/p/5495f87107e7 这篇博文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
